{"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# keras module for building LSTM \nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nimport keras.utils as ku \n\n# set seeds for reproducability\nfrom tensorflow import set_random_seed\nfrom numpy.random import seed\nset_random_seed(2)\nseed(1)\n\nimport pandas as pd\nimport numpy as np\nimport string, os \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-25T10:28:00.689866Z","iopub.execute_input":"2023-04-25T10:28:00.690540Z","iopub.status.idle":"2023-04-25T10:28:03.595695Z","shell.execute_reply.started":"2023-04-25T10:28:00.690466Z","shell.execute_reply":"2023-04-25T10:28:03.594915Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"curr_dir = '../input/'\nall_headlines = []\nfor filename in os.listdir(curr_dir):\n    if 'Articles' in filename:\n        article_df = pd.read_csv(curr_dir + filename)\n        all_headlines.extend(list(article_df.headline.values))\n        break\n\nall_headlines = [h for h in all_headlines if h != \"Unknown\"]\nlen(all_headlines)","metadata":{"_uuid":"87836e3adbe046dd0db62013491ba62bae93b6be","_cell_guid":"b8ef1429-ff19-4a6c-92d7-af8cc61c55f7","execution":{"iopub.status.busy":"2023-04-25T10:31:21.635953Z","iopub.execute_input":"2023-04-25T10:31:21.636716Z","iopub.status.idle":"2023-04-25T10:31:21.691361Z","shell.execute_reply.started":"2023-04-25T10:31:21.636633Z","shell.execute_reply":"2023-04-25T10:31:21.690395Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"829"},"metadata":{}}]},{"cell_type":"code","source":"def clean_text(txt):\n    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n    return txt \n\ncorpus = [clean_text(x) for x in all_headlines]\ncorpus[:10]","metadata":{"_uuid":"2a07365a27a7ba2f92fc9ba4d05d8e6254a68d8c","_cell_guid":"b8bf84ed-da11-4f89-a584-9dceea677420","execution":{"iopub.status.busy":"2023-04-25T10:31:23.087835Z","iopub.execute_input":"2023-04-25T10:31:23.088173Z","iopub.status.idle":"2023-04-25T10:31:23.103543Z","shell.execute_reply.started":"2023-04-25T10:31:23.088111Z","shell.execute_reply":"2023-04-25T10:31:23.102341Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['nfl vs politics has been battle all season long',\n 'voice vice veracity',\n 'a standups downward slide',\n 'new york today a groundhog has her day',\n 'a swimmers communion with the ocean',\n 'trail activity',\n 'super bowl',\n 'trumps mexican shakedown',\n 'pences presidential pet',\n 'fruit of a poison tree']"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = Tokenizer()\n\ndef get_sequence_of_tokens(corpus):\n    ## tokenization\n    tokenizer.fit_on_texts(corpus)\n    total_words = len(tokenizer.word_index) + 1\n    \n    ## convert data to sequence of tokens \n    input_sequences = []\n    for line in corpus:\n        token_list = tokenizer.texts_to_sequences([line])[0]\n        for i in range(1, len(token_list)):\n            n_gram_sequence = token_list[:i+1]\n            input_sequences.append(n_gram_sequence)\n    return input_sequences, total_words\n\ninp_sequences, total_words = get_sequence_of_tokens(corpus)\ninp_sequences[:10]","metadata":{"_uuid":"9129a8b773feb72eff91aa0025157a173d10c625","_cell_guid":"896543c9-7944-4748-b8ef-ef8cbc2a84f0","execution":{"iopub.status.busy":"2023-04-25T10:31:23.463626Z","iopub.execute_input":"2023-04-25T10:31:23.463959Z","iopub.status.idle":"2023-04-25T10:31:23.514349Z","shell.execute_reply.started":"2023-04-25T10:31:23.463907Z","shell.execute_reply":"2023-04-25T10:31:23.513518Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[[660, 117],\n [660, 117, 72],\n [660, 117, 72, 73],\n [660, 117, 72, 73, 661],\n [660, 117, 72, 73, 661, 662],\n [660, 117, 72, 73, 661, 662, 63],\n [660, 117, 72, 73, 661, 662, 63, 29],\n [660, 117, 72, 73, 661, 662, 63, 29, 210],\n [211, 663],\n [211, 663, 664]]"},"metadata":{}}]},{"cell_type":"code","source":"def generate_padded_sequences(input_sequences):\n    max_sequence_len = max([len(x) for x in input_sequences])\n    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n    \n    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n    label = ku.to_categorical(label, num_classes=total_words)\n    return predictors, label, max_sequence_len\n\npredictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)","metadata":{"_uuid":"ca588b414e70e21bebcead960f6632805d37dd8c","_cell_guid":"73254551-40bd-45b1-a7a5-88fe4cbe0b20","execution":{"iopub.status.busy":"2023-04-25T10:31:23.731390Z","iopub.execute_input":"2023-04-25T10:31:23.731725Z","iopub.status.idle":"2023-04-25T10:31:23.785489Z","shell.execute_reply.started":"2023-04-25T10:31:23.731662Z","shell.execute_reply":"2023-04-25T10:31:23.784425Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_model(max_sequence_len, total_words):\n    input_len = max_sequence_len - 1\n    model = Sequential()\n    \n    # Add Input Embedding Layer\n    model.add(Embedding(total_words, 10, input_length=input_len))\n    \n    # Add Hidden Layer 1 - LSTM Layer\n    model.add(LSTM(100))\n    model.add(Dropout(0.1))\n    \n    # Add Output Layer\n    model.add(Dense(total_words, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    \n    return model\n\nmodel = create_model(max_sequence_len, total_words)\nmodel.summary()","metadata":{"_uuid":"76ef6d9352002d333a7c75e8aed7ce996015f527","_cell_guid":"60d6721e-e40e-4f2b-8f63-c06459d68f26","execution":{"iopub.status.busy":"2023-04-25T10:31:24.095834Z","iopub.execute_input":"2023-04-25T10:31:24.096398Z","iopub.status.idle":"2023-04-25T10:31:24.499192Z","shell.execute_reply.started":"2023-04-25T10:31:24.096104Z","shell.execute_reply":"2023-04-25T10:31:24.498356Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 16, 10)            22880     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 100)               44400     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 2288)              231088    \n=================================================================\nTotal params: 298,368\nTrainable params: 298,368\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Lets train our model now","metadata":{"_uuid":"f0b16b471969dbb831cb0024e303341e11b63de4","_cell_guid":"1826aa1a-cb77-4379-a69d-e9b180945dce"}},{"cell_type":"code","source":"model.fit(predictors, label, epochs=100, verbose=5)","metadata":{"_uuid":"156f3303b8120cc6932e6db985cbea4a7ceb08bf","_cell_guid":"07d5cf03-d171-4993-9f8b-18446649ecb0","execution":{"iopub.status.busy":"2023-04-25T10:31:24.500696Z","iopub.execute_input":"2023-04-25T10:31:24.501040Z","iopub.status.idle":"2023-04-25T10:37:06.635181Z","shell.execute_reply.started":"2023-04-25T10:31:24.500976Z","shell.execute_reply":"2023-04-25T10:37:06.634358Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/100\nEpoch 2/100\nEpoch 3/100\nEpoch 4/100\nEpoch 5/100\nEpoch 6/100\nEpoch 7/100\nEpoch 8/100\nEpoch 9/100\nEpoch 10/100\nEpoch 11/100\nEpoch 12/100\nEpoch 13/100\nEpoch 14/100\nEpoch 15/100\nEpoch 16/100\nEpoch 17/100\nEpoch 18/100\nEpoch 19/100\nEpoch 20/100\nEpoch 21/100\nEpoch 22/100\nEpoch 23/100\nEpoch 24/100\nEpoch 25/100\nEpoch 26/100\nEpoch 27/100\nEpoch 28/100\nEpoch 29/100\nEpoch 30/100\nEpoch 31/100\nEpoch 32/100\nEpoch 33/100\nEpoch 34/100\nEpoch 35/100\nEpoch 36/100\nEpoch 37/100\nEpoch 38/100\nEpoch 39/100\nEpoch 40/100\nEpoch 41/100\nEpoch 42/100\nEpoch 43/100\nEpoch 44/100\nEpoch 45/100\nEpoch 46/100\nEpoch 47/100\nEpoch 48/100\nEpoch 49/100\nEpoch 50/100\nEpoch 51/100\nEpoch 52/100\nEpoch 53/100\nEpoch 54/100\nEpoch 55/100\nEpoch 56/100\nEpoch 57/100\nEpoch 58/100\nEpoch 59/100\nEpoch 60/100\nEpoch 61/100\nEpoch 62/100\nEpoch 63/100\nEpoch 64/100\nEpoch 65/100\nEpoch 66/100\nEpoch 67/100\nEpoch 68/100\nEpoch 69/100\nEpoch 70/100\nEpoch 71/100\nEpoch 72/100\nEpoch 73/100\nEpoch 74/100\nEpoch 75/100\nEpoch 76/100\nEpoch 77/100\nEpoch 78/100\nEpoch 79/100\nEpoch 80/100\nEpoch 81/100\nEpoch 82/100\nEpoch 83/100\nEpoch 84/100\nEpoch 85/100\nEpoch 86/100\nEpoch 87/100\nEpoch 88/100\nEpoch 89/100\nEpoch 90/100\nEpoch 91/100\nEpoch 92/100\nEpoch 93/100\nEpoch 94/100\nEpoch 95/100\nEpoch 96/100\nEpoch 97/100\nEpoch 98/100\nEpoch 99/100\nEpoch 100/100\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f3aab7d6d30>"},"metadata":{}}]},{"cell_type":"code","source":"def generate_text(seed_text, next_words, model, max_sequence_len):\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        predicted = model.predict_classes(token_list, verbose=0)\n        \n        output_word = \"\"\n        for word,index in tokenizer.word_index.items():\n            if index == predicted:\n                output_word = word\n                break\n        seed_text += \" \"+output_word\n    return seed_text.title()","metadata":{"_uuid":"e71e56543b7065f115a05e3fd062262b3b94ad46","execution":{"iopub.status.busy":"2023-04-25T10:37:06.636606Z","iopub.execute_input":"2023-04-25T10:37:06.636889Z","iopub.status.idle":"2023-04-25T10:37:06.643757Z","shell.execute_reply.started":"2023-04-25T10:37:06.636848Z","shell.execute_reply":"2023-04-25T10:37:06.642307Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print (generate_text(\"united states\", 5, model, max_sequence_len))\nprint (generate_text(\"preident trump\", 4, model, max_sequence_len))\nprint (generate_text(\"donald trump\", 4, model, max_sequence_len))\nprint (generate_text(\"india and china\", 4, model, max_sequence_len))\nprint (generate_text(\"new york\", 4, model, max_sequence_len))\nprint (generate_text(\"science and technology\", 5, model, max_sequence_len))","metadata":{"_uuid":"a21548224c9e661a29e3d369e348aada0599bdc9","_cell_guid":"e38dd280-093b-4091-b82b-9aa90045b107","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-04-25T10:37:06.645589Z","iopub.execute_input":"2023-04-25T10:37:06.645879Z","iopub.status.idle":"2023-04-25T10:37:06.870637Z","shell.execute_reply.started":"2023-04-25T10:37:06.645834Z","shell.execute_reply":"2023-04-25T10:37:06.869671Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"United States Vs No Colin Firth A\nPreident Trump Mailbag Deconstructed New Isnt\nDonald Trump Master For 24 Hours\nIndia And China And Hand Days A\nNew York Today A Makeshift Law\nScience And Technology In The New Loss In\n","output_type":"stream"}]}]}